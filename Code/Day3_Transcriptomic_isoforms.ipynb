{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Day 3: Transcriptomic Isoforms - Nanopore cDNA Sequencing Pipeline\n",
        "\n",
        "## Bash Introduction\n",
        "### Overview\n",
        "\n",
        "This notebook demonstrates a bioinformatics pipeline designed to analyze nanopore cDNA sequencing data, specifically aimed at quantifying transcript isoforms and assessing alternative splicing events. The pipeline includes four main steps:\n",
        "\n",
        "1. **Indexing reference genomes/transcriptomes** using `minimap2`.\n",
        "2. **Read mapping** using `minimap2`, aligning nanopore sequencing reads to both a reference transcriptome (for quantification) and a reference genome (for visualization).\n",
        "3. **Conversion to BAM format** with `samtools`, preparing alignment data for downstream analysis.\n",
        "4. **Transcript quantification** using `salmon`, which estimates the abundance of transcript isoforms, particularly useful for alternative splicing analyses.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Experimental Setup\n",
        "\n",
        "The dataset used here comprises 12 barcoded samples divided into treatment groups and cellular fractions:\n",
        "\n",
        "- **Barcode 01-03**: Nuclear fraction, exposed to light\n",
        "- **Barcode 04-06**: Nuclear fraction, maintained in dark conditions\n",
        "- **Barcode 07-09**: Cytoplasmic fraction, exposed to light\n",
        "- **Barcode 10-12**: Cytoplasmic fraction, maintained in dark conditions\n",
        "\n",
        "These groupings allow us to investigate the cellular localization and treatment effects on transcript isoform abundance and splicing patterns.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Basecalling and Demultiplexing (Previously Performed)\n",
        "\n",
        "The raw nanopore sequencing data were basecalled and demultiplexed as follows:\n",
        "\n",
        "*The dorado basecaller uses `.POD5` as input, so if you are using old sequencing data, `.fast5 -> .POD5` conversion should be performed.*\n",
        "```bash\n",
        "# Convert FAST5 to POD5 format\n",
        "pod5 convert fast5 /path/to/fast5/*.fast5 --output /path/to/pod5/\n",
        "\n",
        "# Basecalling with Dorado\n",
        "# SQK-PCB109 is the sequencing kit name\n",
        "# \"sup\" indicates the use of a high-accuracy basecalling model\n",
        "dorado basecaller sup /path/to/pod5 --kit-name SQK-PCB109 --verbose -o /path/to/basecalling\n",
        "\n",
        "# Barcode demultiplexing\n",
        "# '--no-classify' is used since classification occurred during basecalling\n",
        "dorado demux --output-dir /path/to/basecalling/barcodes --no-classify --emit-fastq /path/to/basecalling/basecalled_reads.bam\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### File Paths and Parameters\n",
        "\n",
        "Define paths for input and output files and set parameters for computational efficiency:\n",
        "\n",
        "*Here we are defining variables in bash programming laguage for latter use*\n",
        "\n",
        "```bash\n",
        "# Base directory - This is the directory from your local machine!\n",
        "BASE_DIR=\"/mnt/elytron_ssd\"\n",
        "\n",
        "# Input directories and files\n",
        "FASTQ_DIR=\"${BASE_DIR}/ONT_RNA_workshop/ont_raw_data/cDNA/barcodes\"\n",
        "TRANSCRIPTOME_FA=\"{BASE_DIR}/ONT_RNA_workshop/Arabidopsis_references/transcriptome/AtRTDv2_1_QUASI.LS.fa\"\n",
        "GENOME_FA=\"{BASE_DIR}/ONT_RNA_workshop/Arabidopsis_references/genome/TAIR10_mod.fna\"\n",
        "\n",
        "# Indexes\n",
        "MINIMAP2_INDEX_TRANSCRIPTOME=\"{BASE_DIR}/ONT_RNA_workshop/Arabidopsis_references/transcriptome/minimap2_index_transcriptome\"\n",
        "MINIMAP2_INDEX_GENOME=\"{BASE_DIR}/ONT_RNA_workshop/Arabidopsis_references/genome/minimap2_index_genome\"\n",
        "\n",
        "# Output directories\n",
        "BAM_DIR_TRANSCRIPTOME=\"{BASE_DIR}/ONT_RNA_workshop/3.1_Transcriptomics/mapping/minimap2/transcriptome\"\n",
        "BAM_DIR_GENOME=\"{BASE_DIR}/ONT_RNA_workshop/3.1_Transcriptomics/mapping/minimap2/genome\"\n",
        "SALMON_DIR=\"{BASE_DIR}/ONT_RNA_workshop/3.1_Transcriptomics/mapping/salmon\"\n",
        "\n",
        "# Computational parameters (computers cores available)\n",
        "THREADS=8\n",
        "```\n",
        "\n",
        "*In bash, this variables can be called by using a `$` before their name.*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Processing Pipeline\n",
        "\n",
        "#### Step 1: Indexing Reference Genome and Transcriptome\n",
        "Create minimap2 indexes for efficient mapping.\n",
        "\n",
        "*In Bash, including double quotes (\" \") around variables is crucial for correct and safe handling of values, especially when they might contain spaces or special characters.*\n",
        "```bash\n",
        "minimap2 -d \"$MINIMAP2_INDEX_TRANSCRIPTOME\" \"$TRANSCRIPTOME_FA\"\n",
        "minimap2 -d \"$MINIMAP2_INDEX_GENOME\" \"$GENOME_FA\"\n",
        "```\n",
        "\n",
        "#### Step 2: Prepare Output Directories\n",
        "*`mkdir` creates the folder in the system, this is a safe practice to avoid errors if the directory is missing.*\n",
        "```bash\n",
        "mkdir -p \"$BAM_DIR_TRANSCRIPTOME\"\n",
        "mkdir -p \"$BAM_DIR_GENOME\"\n",
        "mkdir -p \"$SALMON_DIR\"\n",
        "```\n",
        "\n",
        "#### Step 3: Loop through each FASTQ file\n",
        "- **Map reads to the transcriptome** for quantification.\n",
        "- **Map reads to the genome** for visualization (e.g., IGV).\n",
        "- **Convert alignments to BAM**.\n",
        "- **Quantify isoforms with salmon**.\n",
        "\n",
        "*This FOR LOOP iterates over each of the `.fastq` files from the `$FASTQ_DIR`.*\n",
        "\n",
        "```bash\n",
        "for FASTQ_FILE in \"$FASTQ_DIR\"/*.fastq; do\n",
        "    FILENAME=$(basename \"$FASTQ_FILE\" .fastq)\n",
        "\n",
        "    # Transcriptome alignment\n",
        "    minimap2 -t $THREADS -a -x map-ont \"$MINIMAP2_INDEX_TRANSCRIPTOME\" \"$FASTQ_FILE\" | \\\n",
        "    samtools view -Sb > \"$BAM_DIR_TRANSCRIPTOME/$FILENAME.bam\"\n",
        "\n",
        "    # Genome alignment\n",
        "    minimap2 -t $THREADS -a -x splice \"$MINIMAP2_INDEX_GENOME\" \"$FASTQ_FILE\" | \\\n",
        "    samtools view -Sb > \"$BAM_DIR_GENOME/$FILENAME.bam\"\n",
        "\n",
        "    # Quantification with salmon\n",
        "    salmon quant --ont -p $THREADS \\\n",
        "        -t \"$TRANSCRIPTOME_FA\" \\\n",
        "        -l U \\\n",
        "        -a \"$BAM_DIR_TRANSCRIPTOME/$FILENAME.bam\" \\\n",
        "        -o \"$SALMON_DIR/$FILENAME\"\n",
        "done\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Final Outputs\n",
        "\n",
        "Results from this pipeline are essential for downstream analyses such as differential isoform expression, alternative splicing events, and visualization of splice variants.\n"
      ],
      "metadata": {
        "id": "G6MZSyh1eG0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding time!\n",
        "\n",
        "Let's start by peeking inside a POD5. This is the nanopore rawdata.\n",
        "POD5 contain the measurements of each read when it passed through the pore. The measurement is in pico Amperes (pA), a current measure, and the variation on this signal is what the `dorado` basecalling models uses to predict which K-mer of bases was passing at the time.\n",
        "\n",
        "To read this files (and see the signal) we will use the Nanopore POD5 library (https://pod5-file-format.readthedocs.io)."
      ],
      "metadata": {
        "id": "JF1AVq6xG4YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path of the salmon files\n",
        "BASE_DIR = \"/media/lucas-elytron/2dec6b70-df64-4e8e-a677-35391317a9a0\"\n",
        "FAST5_EXAMPLE = os.path.join(BASE_DIR, \"ONT_RNA_workshop\", \"ont_raw_data\", \"RNA\")\n",
        "SALMON_DIR = os.path.join(BASE_DIR, \"ONT_RNA_workshop\", \"3.1_Transcriptomics\", \"mapping\", \"salmon\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"ONT_RNA_workshop\", \"3.1_Transcriptomics\", \"outputs\")"
      ],
      "metadata": {
        "id": "IwsYbeGbZBhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⬇️ run this once; the rest of the cell is pure Python\n",
        "!pip -q install pod5 matplotlib"
      ],
      "metadata": {
        "id": "piMA9rmKZs5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pod5\n",
        "import itertools, matplotlib.pyplot as plt\n",
        "import pprint\n",
        "\n",
        "# ── 1) Describe the POD5 structure ───────────────────────────────────────────────────────────────\n",
        "def describe_pod5(fpath, n_preview_fields=10):\n",
        "    with pod5.Reader(fpath) as rdr:\n",
        "        n_reads = rdr.num_reads\n",
        "        print(f\"\\n📄  File : {fpath}\")\n",
        "        print(f\"🧮  Total reads : {n_reads}\")\n",
        "        #\n",
        "        first = next(rdr.reads())\n",
        "        cols = [k for k in dir(first)\n",
        "                if not k.startswith(\"_\")\n",
        "                and k != \"signal\"\n",
        "                and not callable(getattr(first, k))]\n",
        "        #\n",
        "        print(\"📑  Columns :\", \", \".join(cols) if cols else \"(schema unavailable)\")\n",
        "        first = next(rdr.reads())\n",
        "        keys = [k for k in dir(first) if not k.startswith(\"_\") and k != \"signal\"]\n",
        "        preview = {}\n",
        "        for k in keys[:n_preview_fields]:\n",
        "            v = getattr(first, k)\n",
        "            if hasattr(v, \"__len__\") and not isinstance(v, (str, bytes)):\n",
        "                preview[k] = f\"<{type(v).__name__} len={len(v)}>\"\n",
        "            else:\n",
        "                preview[k] = v\n",
        "        print(\"🔍  First read metadata preview:\")\n",
        "        pprint.pprint(preview, compact=True, sort_dicts=False)\n",
        "        print(\"\\n\")\n",
        "\n",
        "# ── 2) LOAD the file as needed ───────────────────────────────────────────────────────────────\n",
        "def load_first_reads(fpath, n=2):\n",
        "    with pod5.Reader(fpath) as rdr:\n",
        "        traces = [(str(r.read_id), r.signal)\n",
        "                    for r in itertools.islice(rdr.reads(), n)]\n",
        "    ylabel = \"Signal (pA)\"\n",
        "    return traces, ylabel\n",
        "\n",
        "# ── 3) PLOT ───────────────────────────────────────────────────────────────\n",
        "def plot_squiggles(traces, ylabel):\n",
        "    \"\"\"\n",
        "    Draw one subplot per trace where\n",
        "        traces = [(read_id, signal), ...]\n",
        "    \"\"\"\n",
        "    print(\"# Plotting The electric signal:\\n\")\n",
        "    fig, axes = plt.subplots(len(traces), 1, figsize=(12, 3*len(traces)))\n",
        "    if len(traces) == 1:                        # matplotlib quirk\n",
        "        axes = [axes]\n",
        "    for ax, (rid, sig) in zip(axes, traces):\n",
        "        ax.plot(sig, lw=0.5)\n",
        "        ax.set_title(f\"Read: {rid}\")\n",
        "        ax.set_xlabel(\"Sample index\")\n",
        "        ax.set_ylabel(ylabel)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "0a0wLE3e98GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Small snippet to upload a file to colab.\n",
        "# Load the .POD5 sample file\n",
        "uploaded = files.upload()\n",
        "FILE = next(iter(uploaded))                   # e.g. \"sample_20reads.pod5\""
      ],
      "metadata": {
        "id": "z7_NAG2eEzJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Brief POD5 description\n",
        "describe_pod5(FILE)\n",
        "\n",
        "# Read and parse the POD5 file\n",
        "traces, ylab = load_first_reads(FILE, n=2)\n",
        "\n",
        "# students can explore `traces` here, e.g. print(len(traces[0][1]))\n",
        "plot_squiggles(traces, ylabel=ylab)"
      ],
      "metadata": {
        "id": "b86DRD_aBvGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Data analysis\n",
        "\n",
        "Now it's time for coding! This script is intented as a guide to help you load the data from SALMON to have some insights on the data."
      ],
      "metadata": {
        "id": "FIeqle0RW8ll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OnsXaVbeEEZ"
      },
      "outputs": [],
      "source": [
        "# Libraries to handle files from the system\n",
        "import os, sys\n",
        "# Library to load dataframes, filter and parse data\n",
        "import pandas as pd  # 'as pd' works as an alias for the pandas library (common practice)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading SALMON Output.\n",
        "\n",
        "Since SALMON outputs one folder for each sample we want to extract only the `quant.sf` from each dir.\n",
        "\n",
        "The following script copies every quant.sf file and renames it as the containing folder name (You can copy and paste this script to the terminal):\n",
        "\n",
        "*Remember to define the base directory!*\n",
        "\n",
        "```bash\n",
        "BASE_DIR=\"/mnt/elytron_ssd\"\n",
        "\n",
        "# Input directory containing all barcode folders\n",
        "INPUT_DIR=\"${BASE_DIR}/ONT_RNA_workshop/3.1_Transcriptomics/mapping/salmon\"\n",
        "\n",
        "# Output directory to store renamed quant.sf files\n",
        "OUTPUT_DIR=\"${BASE_DIR}/ONT_RNA_workshop/3.1_Transcriptomics/mapping/salmon/colab_quant_files\"\n",
        "echo \"$OUTPUT_DIR\"\n",
        "# Create the output directory if it doesn't exist\n",
        "mkdir -p \"$OUTPUT_DIR\"\n",
        "\n",
        "# Find and copy each quant.sf file\n",
        "find \"$INPUT_DIR\" -type f -name \"quant.sf\" | while read filepath; do\n",
        "    # Get the folder name containing the quant.sf\n",
        "    folder_name=$(basename \"$(dirname \"$filepath\")\")\n",
        "    \n",
        "    # Define new filename and destination\n",
        "    new_filename=\"${folder_name}.sf\"\n",
        "    cp \"$filepath\" \"$OUTPUT_DIR/$new_filename\"\n",
        "    \n",
        "    echo \"Copied $filepath to $OUTPUT_DIR/$new_filename\"\n",
        "done\n",
        "\n",
        "echo \"✅ All quant.sf files copied and renamed.\"\n",
        "\n",
        "```\n",
        "\n",
        "*(Paste on the terminal using Ctrl+Shift+V)*"
      ],
      "metadata": {
        "id": "n2pzIg-LRd72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# List SALMON quant files:\n",
        "# Upload all the .sf files together (hold Ctrl/Cmd to select multiple)\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "qRCXNdPKVa8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Build a new list for TPM-only dataframes\n",
        "tpm_tables = []\n",
        "\n",
        "for filename, filecontent in uploaded.items():\n",
        "    sample_name = filename.split(\"_\")[1].replace(\".sf\", \"\")     # Get the name from the filename\n",
        "    df = pd.read_csv(StringIO(filecontent.decode()), sep='\\t')  # Load each table as a pandas df\n",
        "    df = df.set_index('Name')                                   # Set the isoform 'Name' as index\n",
        "\n",
        "    tpm = df[['TPM']].rename(columns={'TPM': sample_name})      # Keep only TPM column and rename it to sample name\n",
        "    tpm_tables.append(tpm)\n",
        "\n",
        "tpm_combined = pd.concat(tpm_tables, axis=1)                    # Merge all dataframes (TPM)\n",
        "tpm_combined[\"Gene\"] = tpm_combined.index.str.slice(0, 9)       # Extract gene name for later grouping\n",
        "\n",
        "# Sorting the columns\n",
        "barcode_order = [\n",
        "    \"barcode01\", \"barcode02\", \"barcode03\", \"barcode04\", \"barcode05\", \"barcode06\",\n",
        "    \"barcode07\", \"barcode08\", \"barcode09\", \"barcode10\", \"barcode11\", \"barcode12\"\n",
        "]\n",
        "sorted_columns = ['Gene'] + barcode_order\n",
        "tpm_combined = tpm_combined[sorted_columns]\n",
        "\n",
        "tpm_combined.head()"
      ],
      "metadata": {
        "id": "eT1XezsxVayZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ All Samples Loaded\n",
        "\n",
        "We have successfully loaded all the samples into a single DataFrame, where each row represents a transcript (identified by its `Name`), and each column corresponds to a different sample.\n",
        "\n",
        "This unified format allows us to easily compare transcript expression levels **across samples** and **search for specific genes of interest**.\n",
        "\n",
        "---\n",
        "\n",
        "### 📊 About SALMON Outputs\n",
        "\n",
        "Salmon provides two key metrics for transcript quantification:\n",
        "\n",
        "- **NumReads**: the estimated number of reads assigned to each transcript.\n",
        "- **TPM (Transcripts Per Million)**: a normalized measure of transcript abundance that accounts for both sequencing depth and transcript length.\n",
        "\n",
        "Unlike raw read counts, **TPMs are directly comparable across samples**, making them especially useful for visualization and interpretation.\n",
        "\n",
        "> 🔍 In this notebook, we'll focus on **TPM values** to explore expression patterns between conditions or samples.\n"
      ],
      "metadata": {
        "id": "7wDlMKBtcrvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gene_of_interest = \"AT3G61860\"\n",
        "tpm_combined[tpm_combined[\"Gene\"] == gene_of_interest]"
      ],
      "metadata": {
        "id": "hjPqxbe8ZFXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hTmhkKALeYDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative-splicing quantification on chr3 with SUPPA 2\n",
        "\n",
        "We will:\n",
        "\n",
        "1. **Install SUPPA 2**  \n",
        "2. **Generate alternative-splicing events** from the _AtRTDv2_ chr3 GTF  \n",
        "3. **Build a transcript-TPM matrix** from the 12 Salmon quantifications  \n",
        "4. **Compute PSI (Ψ) values per event** across all samples  \n",
        "\n",
        "> **Paths used below**  \n",
        "> *GTF* : `/mnt/elytron_ssd/ONT_RNA_workshop/Arabidopsis_references/transcriptome/AtRTDv2_1_QUASI_chr3.gtf`  \n",
        "> *Salmon outputs* : `/mnt/elytron_ssd/ONT_RNA_workshop/3.1_Transcriptomics/mapping/salmon/colab_quant_files/*.sf`  \n",
        "> Adjust if you placed the files somewhere else (e.g. Google Drive).\n",
        "\n",
        "---\n",
        "\n",
        "### 1) Install SUPPA 2\n",
        "Suppa2 can be easily installed like this:\n",
        "```bash\n",
        "pip install --quiet suppa==2.3\n",
        "````\n",
        "\n",
        "But since the last version (2.4) is still not pip installable, we have cloned suppa repository to the `tools` folder.\n",
        "\n",
        "Inside suppa folder, look for the `suppa.py` file!\n",
        "\n",
        "`/.../ONT_RNA_workshop/tools/SUPPA-2.4/suppa.py`\n",
        "\n",
        "###############################################\n",
        "\n",
        "\\### **REPLACE THE `/.../` FOR THE PROPER DIRECTORY!** ####\n",
        "###############################################\n",
        "\n",
        "---\n",
        "\n",
        "### 2) Generate splicing-event annotation (`.ioi`)\n",
        "\n",
        "```bash\n",
        "python /.../ONT_RNA_workshop/tools/SUPPA-2.4/suppa.py generateEvents \\\n",
        "    -i /.../ONT_RNA_workshop/Arabidopsis_references/transcriptome/AtRTDv2_1_QUASI_chr3.gtf \\\n",
        "    -o AtRTDv2_chr3 \\\n",
        "    -f ioi\n",
        "```\n",
        "\n",
        "Creates `AtRTDv2_chr3.ioi` file\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Build the transcript-TPM matrix *from the Pandas DataFrame you already loaded*\n",
        "\n",
        "> We have a DataFrame named **`tpm_combined`** where  \n",
        "> &nbsp;&nbsp;• the *index* = **transcript IDs** (e.g. `AT3G01040.1`)  \n",
        "> &nbsp;&nbsp;• the first column = **gene ID** (optional for SUPPA)  \n",
        "> &nbsp;&nbsp;• the remaining 12 columns = TPM values for each barcode sample  \n",
        ">   \n",
        "> SUPPA’s `psiPerEvent` just needs a **tab-separated file** whose first column is the\n",
        "> transcript ID and the header row lists the sample names.  \n",
        "> We can write it straight from the DataFrame:\n"
      ],
      "metadata": {
        "id": "RHgDme8eeYbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the index and the 'Gene' column\n",
        "#base_cols = ['Name']\n",
        "\n",
        "# Define barcode groups\n",
        "groups = {\n",
        "    'Nuc_light': ['barcode01', 'barcode02', 'barcode03'],\n",
        "    'Nuc_dark': ['barcode04', 'barcode05', 'barcode06'],\n",
        "    'Cit_light': ['barcode07', 'barcode08', 'barcode09'],\n",
        "    'Cit_dark': ['barcode10', 'barcode11', 'barcode12']\n",
        "}\n",
        "\n",
        "# Split and store\n",
        "df_groups = {}\n",
        "for group_name, barcodes in groups.items():\n",
        "    df_groups[group_name] = tpm_combined[barcodes] # base_cols +\n",
        "\n",
        "for group_name, sub_df in df_groups.items():\n",
        "    sub_df.to_csv(f\"{group_name}_TPM.tsv\", sep='\\t', index=True)\n"
      ],
      "metadata": {
        "id": "3crqxwU9fSFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Look for the file on the right panel of Colab. It's under the folder Icon*\n",
        "\n",
        "**<--- (Check for the file on the left and download it!)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 4) Compute Ψ for each isoform (IOI)\n",
        "\n",
        "```bash\n",
        "python /.../ONT_RNA_workshop/tools/SUPPA-2.4/suppa.py psiPerIsoform \\\n",
        "  -g AtRTDv2_chr3.ioi \\\n",
        "  -e Nuc_light.tsv \\\n",
        "  -o Nuc_light\n",
        "````\n",
        "\n",
        "Output **`Nuc_light.psi`**\n",
        "*Rows* = transcripts  *Columns* = 12 barcodes  *Values* = Ψ (isoform usage).\n",
        "\n",
        "---\n",
        "\n",
        "### 5) Compare light vs dark nuclei (group-comparison)\n",
        "\n",
        "The command below performs an **empirical group comparison** (`-gc`) between the\n",
        "*light* and *dark* nuclei conditions, using:\n",
        "\n",
        "* **Input annotation** `AtRTDv2_chr3.ioi`\n",
        "* **Per-condition Ψ matrices** `Nuc_light_TPM_isoform.psi` and `Nuc_dark_TPM_isoform.psi`\n",
        "* **Per-condition TPM tables** `Nuc_light_TPM.tsv` and `Nuc_dark_TPM.tsv`\n",
        "* **Sliding-window area** `--area 500` (recommended default)\n",
        "\n",
        "```bash\n",
        "SUPPA=\"/.../ONT_RNA_workshop/3.1_Transcriptomics/SUPPA2/\"\n",
        "    \n",
        "python /.../ONT_RNA_workshop/tools/SUPPA-2.4/suppa.py diffSplice \\\n",
        "    -m empirical --combination -th 1 \\\n",
        "    --input \"${SUPPA}AtRTDv2_chr3.ioi\" \\\n",
        "    --psi \"${SUPPA}psi/Nuc_light_TPM_isoform.psi\" \"${SUPPA}psi/Nuc_dark_TPM_isoform.psi\" \"${SUPPA}psi/Cit_light_TPM_isoform.psi\" \"${SUPPA}psi/Cit_dark_TPM_isoform.psi\" \\\n",
        "    --tpm \"${SUPPA}per_condition_dataframe/Nuc_light_TPM.tsv\" \"${SUPPA}per_condition_dataframe/Nuc_dark_TPM.tsv\" \"${SUPPA}per_condition_dataframe/Cit_light_TPM.tsv\" \"${SUPPA}per_condition_dataframe/Cit_dark_TPM.tsv\" \\\n",
        "    --area 500 -gc -o \"${SUPPA}comparisons/nuc_cit_light_dark\"\n",
        "```\n",
        "\n",
        "**Output** `light_dark.dpsi` (and related files):\n",
        "\n",
        "| Column                 | Meaning                                    |\n",
        "| ---------------------- | ------------------------------------------ |\n",
        "| `gene_id` / `event_id` | Gene or transcript being tested            |\n",
        "| `dpsi`                 | ΔΨ between conditions                      |\n",
        "| `p_value`              | Raw empirical p-value                      |\n",
        "| `adj_p_value`          | Benjamini–Hochberg FDR (already corrected) |\n",
        "\n",
        "---\n",
        "\n",
        "### (Quick check of the comparison)\n",
        "\n",
        "```bash\n",
        "head -n 5 /.../ONT_RNA_workshop/3.1_Transcriptomics/SUPPA2/comparisons/light_dark.dpsi | column -t\n",
        "```\n",
        "\n",
        "You now have **differential isoform-usage** results ready for downstream\n",
        "visualisation (volcano plots, heatmaps) or functional enrichment.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "U1cDlGV_eanR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the differential isoform usage comparison\n",
        "\n",
        "Now we wil dive into the SUPPA2 output and make some plots!\n",
        "\n",
        "First of all lest check for the genes with the biggest alternative splicing variations:"
      ],
      "metadata": {
        "id": "qbyryQKr3G6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the file: \"/.../ONT_RNA_workshop/3.1_Transcriptomics/SUPPA2/comparisons/light_dark.dpsi\"\n",
        "uploaded = files.upload()\n",
        "SUPPA_FILE = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "4sRNbcTrDjnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_suppa = pd.read_csv(SUPPA_FILE, sep = \"\\t\")\n",
        "df_suppa.rename(columns=lambda c: c.replace('_TPM_isoform', ''), inplace=True)\n",
        "display(df_suppa.head())\n",
        "# Split the index and create 'gene' and 'isoform' columns\n",
        "df_suppa.index = df_suppa.index.str.split(';', expand=True)\n",
        "\n",
        "df_suppa"
      ],
      "metadata": {
        "id": "xx32oH-BeZQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) pull out the base names of each comparison (strip trailing _dPSI / _p-val)\n",
        "comparisons = sorted({c.rsplit(\"_\", 1)[0] for c in df_suppa.columns})\n",
        "# 2) build a dict of “tidy” data-frames: {comparison: 2-column DF}\n",
        "split_dfs = {\n",
        "    cmp: df_suppa[[f\"{cmp}_dPSI\", f\"{cmp}_p-val\"]].rename(\n",
        "            columns={f\"{cmp}_dPSI\": \"dPSI\", f\"{cmp}_p-val\": \"p_val\"})\n",
        "    for cmp in comparisons\n",
        "}\n",
        "\n",
        "# optional: save each to TSV\n",
        "for cmp, sub in split_dfs.items():\n",
        "    sub.to_csv(f\"{cmp}.tsv\", sep=\"\\t\")\n",
        "    print(\"✅\", cmp, \"→\", f\"{cmp}.tsv\")\n",
        "\n",
        "# quick access example\n",
        "nuc_light_vs_dark = split_dfs[\"Nuc_light-Nuc_dark\"]\n",
        "nuc_light_vs_dark.head()"
      ],
      "metadata": {
        "id": "7u6YrKAF3-J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- user-editable section ----------------------------------\n",
        "contrasts = [\n",
        "    \"Nuc_light-Nuc_dark\",\n",
        "    \"Nuc_light-Cit_light\",\n",
        "    \"Nuc_light-Cit_dark\",\n",
        "    \"Nuc_dark-Cit_light\",\n",
        "    \"Nuc_dark-Cit_dark\",\n",
        "    \"Cit_light-Cit_dark\",\n",
        "]\n",
        "dpsi_cut  = 0.10           # |ΔPSI| threshold\n",
        "p_cut     = 0.05           # raw p threshold  (see §8 for FDR)\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "sig = {\n",
        "    c: (\n",
        "        df_suppa[f\"{c}_p-val\"]   <= p_cut\n",
        "     ) & (\n",
        "        df_suppa[f\"{c}_dPSI\"].abs() >= dpsi_cut\n",
        "     ) & (\n",
        "        df_suppa[f\"{c}_dPSI\"].abs() < 1\n",
        "     )\n",
        "    for c in contrasts\n",
        "}\n",
        "print(sig)"
      ],
      "metadata": {
        "id": "s_ZYW6-o_Vh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def volcano_plot(contrast, ax=None):\n",
        "    x = df_suppa[f\"{contrast}_dPSI\"]\n",
        "    y = -np.log10(df_suppa[f\"{contrast}_p-val\"])\n",
        "    ax = ax or plt.gca()\n",
        "    ax.scatter(x, y, s=8, alpha=.6,\n",
        "               c=sig[contrast].map({True:\"red\", False:\"grey\"}))\n",
        "    ax.axvline( dpsi_cut, ls=\"--\"); ax.axvline(-dpsi_cut, ls=\"--\")\n",
        "    ax.axhline(-np.log10(p_cut), ls=\"--\")\n",
        "    ax.set_xlabel(\"ΔPSI\"); ax.set_ylabel(\"-log10 p-value\")\n",
        "    ax.set_title(f\"Volcano • {contrast}\")\n",
        "\n",
        "volcano_plot(\"Nuc_light-Cit_light\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tr5FVm9c5J_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "dpsi_cols = [c for c in df_suppa.columns if c.endswith(\"_dPSI\")]\n",
        "\n",
        "# Drop rows with NaN values in the dPSI columns and fill any remaining non-finite values with 0\n",
        "df_suppa_cleaned = df_suppa.dropna(subset=dpsi_cols).fillna(0)\n",
        "\n",
        "import seaborn as sns\n",
        "dpsi_cols = [f\"{c}_dPSI\" for c in contrasts]\n",
        "sns.clustermap(\n",
        "    df_suppa_cleaned[dpsi_cols],\n",
        "    cmap=\"vlag\", center=0,\n",
        "    figsize=(10, 8),\n",
        "    yticklabels=False\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rw4JttWS58I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install matplotlib-venn\n",
        "from matplotlib_venn import venn3\n",
        "\n",
        "set1 = set(df_suppa.index[sig[\"Nuc_light-Nuc_dark\"]])\n",
        "set2 = set(df_suppa.index[sig[\"Nuc_light-Cit_light\"]])\n",
        "set3 = set(df_suppa.index[sig[\"Nuc_dark-Cit_light\"]])\n",
        "\n",
        "labels = (\"Nuc L ↔ Nuc D\", \"Nuc L ↔ Cit L\", \"Nuc D ↔ Cit L\")\n",
        "\n",
        "venn3([set1, set2, set3], set_labels=labels)\n",
        "plt.title(\"Significant ΔPSI | Venn diagram\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JZTAMuef_1jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools, seaborn as sns\n",
        "pair_cols = [f\"{c}_dPSI\" for c in contrasts]\n",
        "\n",
        "sns.pairplot(df_suppa[pair_cols], corner=True,\n",
        "             plot_kws=dict(s=8, alpha=.5))\n",
        "plt.suptitle(\"ΔPSI cross-contrast scatter matrix\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0iRYp1MIABcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Import numpy for arange\n",
        "import matplotlib.pyplot as plt # Import matplotlib\n",
        "\n",
        "# --- recalc the two series -------------------------------------------------\n",
        "counts_up   = [(df_suppa[f\"{c}_dPSI\"] >  dpsi_cut).sum()  for c in contrasts]\n",
        "counts_down = [(df_suppa[f\"{c}_dPSI\"] < -dpsi_cut).sum()  for c in contrasts]\n",
        "counts_down = [-n for n in counts_down]   # negate so bars extend downward\n",
        "\n",
        "# --- plot ------------------------------------------------------------------\n",
        "x = np.arange(len(contrasts))\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.bar(x, counts_up,             label=\"+ΔPSI\")         # upward bars\n",
        "ax.bar(x, counts_down,           label=\"-ΔPSI\")         # downward bars\n",
        "ax.axhline(0, color=\"k\", lw=1)                          # zero reference\n",
        "\n",
        "ax.set_xticks(x, contrasts, rotation=45, ha=\"right\")\n",
        "ax.set_ylabel(\"# significant events\")\n",
        "ax.legend()\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eDu_GiE3Al2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install tabulate  (pretty console tables)\n",
        "\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "# ------------------------------------------------------------------\n",
        "# 1.  Load your SUPPA2 data  (already done if df_suppa exists)\n",
        "# df_suppa = pd.read_csv(\"arabidopsis_suppa_output.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "# 2.  Identify ΔPSI columns\n",
        "dpsi_cols = [c for c in df_suppa.columns if c.endswith(\"_dPSI\")]\n",
        "\n",
        "# 3 a.  ---  ISOFORM-LEVEL ranking  --------------------------------\n",
        "df_iso = df_suppa.copy()\n",
        "df_iso[\"max_abs_dPSI\"] = df_iso[dpsi_cols].abs().max(axis=1)\n",
        "\n",
        "top_iso = (\n",
        "    df_iso\n",
        "    .sort_values(\"max_abs_dPSI\", ascending=False)\n",
        "    .head(20)                                    # change to any N you like\n",
        "    [[\"max_abs_dPSI\"] + dpsi_cols]\n",
        "    .round(3)\n",
        ")\n",
        "\n",
        "print(\"\\nTop isoforms by |ΔPSI| in any contrast\")\n",
        "print(tabulate(top_iso, headers=\"keys\", tablefmt=\"github\"))\n",
        "\n",
        "# 3 b.  ---  GENE-LEVEL ranking  -----------------------------------\n",
        "# Access the first level of the MultiIndex for the gene name\n",
        "df_iso[\"gene\"] = df_iso.index.get_level_values(0)\n",
        "\n",
        "gene_summary = (\n",
        "    df_iso\n",
        "      .groupby(\"gene\")[dpsi_cols]\n",
        "      .apply(lambda x: x.abs().max().max())  # max across isoforms & contrasts\n",
        "      .rename(\"gene_max_abs_dPSI\")\n",
        "      .sort_values(ascending=False)\n",
        "      .head(20)\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "print(\"\\nTop genes by |ΔPSI| in any contrast\")\n",
        "print(tabulate(gene_summary, headers=[\"Gene\", \"max |ΔPSI|\"], tablefmt=\"github\", floatfmt=\".3f\"))"
      ],
      "metadata": {
        "id": "OcAlEESfBHZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gJwxVDmIO-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}